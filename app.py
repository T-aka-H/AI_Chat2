import streamlit as st
import pandas as pd
import numpy as np
import json
import re
import random
import os
from typing import Dict, List, Optional, Tuple
from collections import Counter
import math
import time
import requests
from datetime import datetime
import html
import textwrap

# ãƒšãƒ¼ã‚¸ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç°¡æ˜“ç‰ˆï¼‰
def show_page_navigation() -> str:
    """ç¾åœ¨ã¯ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸å›ºå®šã§è¿”ã™ã€‚å¿…è¦ãªã‚‰ã‚¿ãƒ–ã‚„ãƒ©ã‚¸ã‚ªUIã«æ‹¡å¼µå¯ã€‚"""
    return 'chat'

def show_home_page():
    """ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ï¼ˆç¾çŠ¶ã¯ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã«å§”è­²ï¼‰ã€‚"""
    show_chat_page()

def show_extraction_page():
    """æŠ½å‡ºãƒšãƒ¼ã‚¸ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã€‚"""
    st.markdown("### æŠ½å‡ºãƒšãƒ¼ã‚¸\næº–å‚™ä¸­ã§ã™ã€‚å·¦ã®ãƒãƒ£ãƒƒãƒˆè¨­å®šã‹ã‚‰AIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ä¼šè©±ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")

def show_settings_page():
    """è¨­å®šãƒšãƒ¼ã‚¸ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã€‚"""
    st.markdown("### è¨­å®š\nã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ãƒãƒ£ãƒƒãƒˆè¨­å®šã€ã§AIãƒ—ãƒ­ãƒã‚¤ãƒ€ã¨APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

# è¨­å®š
st.set_page_config(
    page_title="ğŸ’¬ å¤§è°·ç¿”å¹³ãƒãƒ£ãƒƒãƒˆ",
    page_icon="âš¾",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS - LINEé¢¨ã‚¹ã‚¿ã‚¤ãƒ«
def load_css():
    st.markdown(textwrap.dedent("""
    <style>
    /* å…¨ä½“ã®èƒŒæ™¯ */
    .main .block-container {
        max-width: 100% !important;
        padding-top: 1rem !important;
        padding-left: 1rem !important;
        padding-right: 1rem !important;
        padding-bottom: 0 !important; /* ä½™ç™½å‰Šé™¤ */
    }
    
    /* ãƒãƒ£ãƒƒãƒˆç”»é¢å…¨ä½“ */
    .chat-app {
        display: flex;
        flex-direction: column;
        height: auto;
        min-height: 50vh;
        max-width: 800px;
        margin: 0 auto;
        background: white;
        box-shadow: 0 0 20px rgba(0,0,0,0.1);
        border-radius: 15px;
        overflow: hidden;
    }
    
    /* ãƒ˜ãƒƒãƒ€ãƒ¼ */
    .chat-header {
        background: #e9ecef; /* ã‚°ãƒ¬ãƒ¼ */
        color: #333;
        padding: 12px 16px;
        text-align: center;
        font-weight: bold;
        font-size: 18px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.08);
        position: relative;
    }
    
    .status-indicator {
        position: absolute;
        right: 20px;
        top: 50%;
        transform: translateY(-50%);
        font-size: 12px;
        display: flex;
        align-items: center;
        gap: 5px;
    }
    
    .online-dot {
        width: 8px;
        height: 8px;
        background: #4CAF50;
        border-radius: 50%;
        animation: pulse 2s infinite;
    }
    
    @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.5; }
        100% { opacity: 1; }
    }
    
    /* ãƒãƒ£ãƒƒãƒˆèƒŒæ™¯ - LINEé¢¨ */
    .chat-background {
        flex: 1;
        background: #f8f9fa;
        background-image: 
            radial-gradient(circle at 20% 50%, rgba(120, 119, 198, 0.03) 0%, transparent 50%),
            radial-gradient(circle at 80% 20%, rgba(120, 119, 198, 0.03) 0%, transparent 50%),
            radial-gradient(circle at 40% 80%, rgba(120, 119, 198, 0.03) 0%, transparent 50%),
            repeating-linear-gradient(
                45deg,
                transparent,
                transparent 2px,
                rgba(120, 119, 198, 0.02) 2px,
                rgba(120, 119, 198, 0.02) 4px
            );
        padding: 20px;
        overflow-y: auto;
        display: flex;
        flex-direction: column;
        gap: 10px;
    }
    
    /* ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå³å´ãƒ»LINEç·‘ï¼‰ */
    .user-message-container {
        display: flex;
        justify-content: flex-end;
        align-items: flex-end;
        gap: 10px;
        margin: 5px 0;
    }
    
    .user-message {
        background: #06c755;
        color: white;
        padding: 12px 16px;
        border-radius: 18px 18px 4px 18px;
        max-width: 70%;
        box-shadow: 0 1px 2px rgba(0,0,0,0.1);
        font-size: 16px;
        line-height: 1.4;
        word-wrap: break-word;
    }
    
    .user-avatar {
        width: 35px;
        height: 35px;
        border-radius: 50%;
        background: #06c755;
        display: flex;
        align-items: center;
        justify-content: center;
        color: white;
        font-weight: bold;
        font-size: 12px;
        flex-shrink: 0;
    }
    
    /* å¤§è°·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå·¦å´ãƒ»ç™½ï¼‰ */
    .ohtani-message-container {
        display: flex;
        justify-content: flex-start;
        align-items: flex-end;
        gap: 10px;
        margin: 5px 0;
    }
    
    .ohtani-avatar {
        width: 35px;
        height: 35px;
        border-radius: 50%;
        background: linear-gradient(135deg, #E3F2FD, #BBDEFB);
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 20px;
        flex-shrink: 0;
        border: 2px solid #90CAF9;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .ohtani-message {
        background: white;
        color: #333;
        padding: 12px 16px;
        border-radius: 18px 18px 18px 4px;
        max-width: 70%;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        font-size: 16px;
        line-height: 1.4;
        word-wrap: break-word;
    }
    
    /* ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— */
    .timestamp {
        font-size: 11px;
        color: #999;
        text-align: center;
        margin: 5px 0;
    }
    
    /* ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    .system-message {
        background: rgba(0,0,0,0.05);
        color: #666;
        padding: 4px 8px;
        border-radius: 8px;
        text-align: center;
        margin: 5px auto 0 auto; /* ä¸‹ãƒãƒ¼ã‚¸ãƒ³ã‚’ãªãã™ */
        max-width: 200px;
        font-size: 10px;
        border: 1px solid rgba(0,0,0,0.05);
    }
    
    /* ã‚¿ã‚¤ãƒ”ãƒ³ã‚°è¡¨ç¤º */
    .typing-container {
        display: flex;
        align-items: flex-end;
        gap: 10px;
        margin: 5px 0;
    }
    
    .typing-indicator {
        background: white;
        color: #999;
        padding: 12px 16px;
        border-radius: 18px 18px 18px 4px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        animation: typing-pulse 1.5s ease-in-out infinite;
        display: flex;
        align-items: center;
        gap: 5px;
    }
    
    @keyframes typing-pulse {
        0% { opacity: 0.6; }
        50% { opacity: 1.0; }
        100% { opacity: 0.6; }
    }
    
    .typing-dots {
        display: flex;
        gap: 3px;
    }
    
    .typing-dot {
        width: 6px;
        height: 6px;
        border-radius: 50%;
        background: #999;
        animation: typing-bounce 1.4s ease-in-out infinite;
    }
    
    .typing-dot:nth-child(1) { animation-delay: 0s; }
    .typing-dot:nth-child(2) { animation-delay: 0.2s; }
    .typing-dot:nth-child(3) { animation-delay: 0.4s; }
    
    @keyframes typing-bounce {
        0%, 80%, 100% { transform: scale(0); }
        40% { transform: scale(1); }
    }
    
    /* ã‚¯ã‚¤ãƒƒã‚¯è¿”ä¿¡ã‚¨ãƒªã‚¢ */
    .quick-replies {
        background: #f8f9fa;
        padding: 10px 15px;
        display: flex;
        flex-wrap: wrap;
        gap: 6px;
        border-top: 1px solid #e9ecef;
        min-height: 50px;
        align-items: center;
    }
    
    .quick-reply-btn {
        background: white;
        color: #666;
        border: 1px solid #e9ecef;
        padding: 6px 12px;
        border-radius: 15px;
        font-size: 13px;
        cursor: pointer;
        transition: all 0.3s ease;
        white-space: nowrap;
    }
    
    .quick-reply-btn:hover {
        background: #06c755;
        color: white;
        border-color: #06c755;
        transform: translateY(-1px);
    }
    
    /* å…¥åŠ›ã‚¨ãƒªã‚¢ */
    .input-area {
        background: #111827; /* ãƒ€ãƒ¼ã‚¯èƒŒæ™¯ */
        padding: 10px 12px;
        display: flex;
        align-items: center;
        gap: 10px;
        border-top: 1px solid #1f2937;
        position: sticky;
        bottom: 0;
        z-index: 5;
        margin-bottom: 0 !important; /* ä½™ç™½ãªãã™ */
    }
    
    /* Streamlitã®å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´ */
    .stTextInput > div > div > input {
        border-radius: 22px !important;
        border: 1px solid #374151 !important;
        background: #0b1220 !important;
        color: #e5e7eb !important;
        padding: 12px 16px !important;
        font-size: 16px !important;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #10b981 !important;
        box-shadow: 0 0 0 2px rgba(16, 185, 129, 0.15) !important;
    }
    
    /* ãƒœã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ« */
    .stButton > button {
        background: #10b981 !important;
        color: white !important;
        border: none !important;
        border-radius: 22px !important;
        padding: 10px 20px !important;
        font-weight: 500 !important;
        transition: all 0.3s ease !important;
    }
    
    .stButton > button:hover {
        background: #0ea5a4 !important;
        transform: translateY(-1px) !important;
        box-shadow: 0 4px 12px rgba(14, 165, 164, 0.3) !important;
    }
    
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚°ãƒ¬ãƒ¼ãƒœã‚¿ãƒ³ */
    .stButton > button[data-testid*="clear_history"], 
    .stButton > button[data-testid*="page_refresh"] {
        background: #6b7280 !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 8px 16px !important;
        font-size: 14px !important;
        font-weight: 400 !important;
        width: 100% !important;
    }
    
    .stButton > button[data-testid*="clear_history"]:hover, 
    .stButton > button[data-testid*="page_refresh"]:hover {
        background: #4b5563 !important;
        transform: none !important;
        box-shadow: none !important;
    }
    
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼éè¡¨ç¤º */
    .css-1d391kg {
        display: none;
    }
    
    /* ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ– */
    @media (max-width: 768px) {
        .chat-app {
            max-width: 100%;
            height: auto;
            min-height: 60vh;
            border-radius: 0;
        }
        
        .user-message, .ohtani-message {
            max-width: 85%;
        }
        
        .chat-background {
        }
    }
    </style>
    """), unsafe_allow_html=True)

# è»½é‡ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ã‚¯ãƒ©ã‚¹
class LightweightTextSearch:
    """è»½é‡TF-IDFæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, texts: List[str], max_features: int = 2000):
        self.texts = texts
        self.max_features = max_features
        self.vocab = self._build_vocabulary()
        self.idf_vector = self._compute_idf()
    
    def _tokenize(self, text: str) -> List[str]:
        """æ—¥æœ¬èªå¯¾å¿œãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        if not isinstance(text, str):
            return []
        
        # åŸºæœ¬ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
        tokens = re.findall(r'[\w\u3040-\u309f\u30a0-\u30ff\u4e00-\u9fff]+', text.lower())
        
        # é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æŠ½å‡ºã¨æ­£è¦åŒ–
        normalized_tokens = []
        for token in tokens:
            if len(token) > 1:
                # é‡çƒé–¢é€£ç”¨èªã®æ­£è¦åŒ–
                if 'æ‰“æ’ƒ' in token or 'ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°' in token or 'æ‰“å¸­' in token:
                    normalized_tokens.extend(['æ‰“æ’ƒ', 'ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°', 'æ‰“å¸­'])
                elif 'æŠ•çƒ' in token or 'ãƒ”ãƒƒãƒãƒ³ã‚°' in token or 'æŠ•æ‰‹' in token:
                    normalized_tokens.extend(['æŠ•çƒ', 'ãƒ”ãƒƒãƒãƒ³ã‚°', 'æŠ•æ‰‹'])
                elif 'ç·´ç¿’' in token or 'ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°' in token:
                    normalized_tokens.extend(['ç·´ç¿’', 'ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°'])
                elif 'åˆå›' in token or 'åˆã‚ã¦' in token or 'ã¯ã˜ã‚ã¦' in token:
                    normalized_tokens.extend(['åˆå›', 'åˆã‚ã¦', 'ã¯ã˜ã‚ã¦'])
                elif 'å±‹å¤–' in token or 'å¤–' in token or 'é‡å¤–' in token:
                    normalized_tokens.extend(['å±‹å¤–', 'å¤–', 'é‡å¤–'])
                elif 'æ„Ÿæƒ³' in token or 'æ„Ÿã˜' in token or 'ã©ã†' in token:
                    normalized_tokens.extend(['æ„Ÿæƒ³', 'æ„Ÿã˜', 'ã©ã†'])
                else:
                    normalized_tokens.append(token)
        
        return list(set(normalized_tokens))  # é‡è¤‡é™¤å»
    
    def _build_vocabulary(self) -> Dict[str, int]:
        """èªå½™è¾æ›¸æ§‹ç¯‰"""
        all_tokens = []
        for text in self.texts:
            all_tokens.extend(self._tokenize(text))
        
        token_counts = Counter(all_tokens)
        top_tokens = [token for token, count in token_counts.most_common(self.max_features)]
        
        return {token: idx for idx, token in enumerate(top_tokens)}
    
    def _compute_tf(self, tokens: List[str]) -> np.ndarray:
        """TFè¨ˆç®—"""
        tf_vector = np.zeros(len(self.vocab))
        if not tokens:
            return tf_vector
            
        token_counts = Counter(tokens)
        total_tokens = len(tokens)
        
        for token, count in token_counts.items():
            if token in self.vocab:
                tf_vector[self.vocab[token]] = count / total_tokens
        
        return tf_vector
    
    def _compute_idf(self) -> np.ndarray:
        """IDFè¨ˆç®—"""
        idf_vector = np.zeros(len(self.vocab))
        num_docs = len(self.texts)
        
        for token, token_idx in self.vocab.items():
            doc_count = sum(1 for text in self.texts if token in self._tokenize(text))
            if doc_count > 0:
                idf_vector[token_idx] = math.log(num_docs / doc_count)
        
        return idf_vector
    
    def _text_to_tfidf(self, text: str) -> np.ndarray:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’TF-IDFãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›"""
        tokens = self._tokenize(text)
        tf_vector = self._compute_tf(tokens)
        return tf_vector * self.idf_vector
    
    def cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦"""
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def search(self, query: str, top_k: int = 5) -> List[Tuple[int, float]]:
        """é¡ä¼¼ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢"""
        query_tfidf = self._text_to_tfidf(query)
        similarities = []
        
        for i, text in enumerate(self.texts):
            text_tfidf = self._text_to_tfidf(text)
            similarity = self.cosine_similarity(query_tfidf, text_tfidf)
            similarities.append((i, similarity))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
class KeywordSearch:
    """è»½é‡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°æ¤œç´¢"""
    
    def __init__(self, texts: List[str]):
        self.texts = texts
        self.keyword_index = self._build_index()
    
    def _tokenize(self, text: str) -> List[str]:
        if not isinstance(text, str):
            return []
        return re.findall(r'[\w\u3040-\u309f\u30a0-\u30ff\u4e00-\u9fff]+', text.lower())
    
    def _build_index(self) -> Dict[str, List[int]]:
        index = {}
        for doc_id, text in enumerate(self.texts):
            tokens = self._tokenize(text)
            for token in set(tokens):
                if len(token) > 1:
                    if token not in index:
                        index[token] = []
                    index[token].append(doc_id)
        return index
    
    def search(self, query: str, top_k: int = 5) -> List[Tuple[int, float]]:
        query_tokens = set(self._tokenize(query))
        doc_scores = {}
        
        for token in query_tokens:
            if token in self.keyword_index:
                for doc_id in self.keyword_index[token]:
                    doc_scores[doc_id] = doc_scores.get(doc_id, 0) + 1
        
        if not doc_scores:
            return []
        
        max_score = max(doc_scores.values())
        results = [(doc_id, score/max_score) for doc_id, score in doc_scores.items()]
        results.sort(key=lambda x: x[1], reverse=True)
        
        return results[:top_k]

# ãƒãƒ£ãƒƒãƒˆç”¨RAGã‚·ã‚¹ãƒ†ãƒ 
class OhtaniChatRAG:
    """å¤§è°·ç¿”å¹³ãƒãƒ£ãƒƒãƒˆç”¨RAGã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, csv_path_or_data):
        if isinstance(csv_path_or_data, pd.DataFrame):
            # DataFrameãŒæ¸¡ã•ã‚ŒãŸå ´åˆ
            self.df = csv_path_or_data
        elif isinstance(csv_path_or_data, str):
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒæ¸¡ã•ã‚ŒãŸå ´åˆ
            self.df = self._load_data(csv_path_or_data)
        else:
            # Noneã¾ãŸã¯ãã®ä»–ã®å ´åˆã¯ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            self.df = self._create_chat_sample_data()
        
        self.questions = self.df['Question'].fillna('').astype(str).tolist()
        self.answers = self.df['Answer'].fillna('').astype(str).tolist()
        
        # æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.tfidf_search = LightweightTextSearch(self.questions)
        self.keyword_search = KeywordSearch(self.questions)
        self.answer_search = KeywordSearch(self.answers)
        
        # å¤§è°·é¸æ‰‹ã®è©±ã—æ–¹ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.ohtani_patterns = self._extract_speech_patterns()
        
        # ãƒãƒ£ãƒƒãƒˆç”¨ã®æŒ¨æ‹¶ãƒ»ç›¸æ§Œãƒ‘ã‚¿ãƒ¼ãƒ³
        self.chat_patterns = self._create_chat_patterns()
    
    def _load_data(self, csv_path: str) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            df = pd.read_csv(csv_path)
            if len(df) < 50:
                parent_path = os.path.join(os.path.dirname(os.path.dirname(csv_path)), "ohtani_rag_final.csv")
                if os.path.exists(parent_path):
                    df = pd.read_csv(parent_path)
            return df
        except FileNotFoundError:
            return self._create_chat_sample_data()
    
    def _create_chat_sample_data(self) -> pd.DataFrame:
        """ãƒãƒ£ãƒƒãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿"""
        questions = [
            # æŒ¨æ‹¶ãƒ»æ—¥å¸¸ä¼šè©±
            'ã“ã‚“ã«ã¡ã¯', 'ãŠã¯ã‚ˆã†', 'ä»Šæ—¥èª¿å­ã¯ã©ã†ï¼Ÿ', 'ãŠç–²ã‚Œã•ã¾',
            'å…ƒæ°—ï¼Ÿ', 'æœ€è¿‘ã©ã†ï¼Ÿ', 'ã“ã‚“ã°ã‚“ã¯', 'ãŠã‚„ã™ã¿',
            
            # é‡çƒé–¢é€£
            'ä»Šæ—¥ã®è©¦åˆã¯ã©ã†ã ã£ãŸï¼Ÿ', 'ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°èª¿å­ã©ã†ï¼Ÿ', 'ãƒ”ãƒƒãƒãƒ³ã‚°ã¯ï¼Ÿ',
            'ãƒãƒ¼ãƒ ã®é›°å›²æ°—ã¯ï¼Ÿ', 'ä»Šã‚·ãƒ¼ã‚ºãƒ³ã®ç›®æ¨™ã¯ï¼Ÿ', 'ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼æ„Ÿã˜ã‚‹ï¼Ÿ',
            
            # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ
            'ä»Šä½•ã—ã¦ã‚‹ï¼Ÿ', 'å¥½ããªé£Ÿã¹ç‰©ã¯ï¼Ÿ', 'è¶£å‘³ã¯ä½•ï¼Ÿ', 'ä¼‘æ—¥ã¯ä½•ã—ã¦ã‚‹ï¼Ÿ',
            'æ˜ ç”»ã¯è¦‹ã‚‹ï¼Ÿ', 'éŸ³æ¥½ã¯èãï¼Ÿ', 'æ—¥æœ¬ãŒæ‹ã—ã„ï¼Ÿ', 'ã‚¢ãƒ¡ãƒªã‚«ã¯ã©ã†ï¼Ÿ',
            
            # åŠ±ã¾ã—ãƒ»å¿œæ´
            'é ‘å¼µã£ã¦ï¼', 'å¿œæ´ã—ã¦ã‚‹ã‚ˆï¼', 'ãƒ•ã‚¡ã‚¤ãƒˆï¼', 'è² ã‘ãªã„ã§ï¼',
            'ç´ æ™´ã‚‰ã—ã„ãƒ—ãƒ¬ãƒ¼ã ã£ãŸ', 'ã™ã”ã„ã­ï¼', 'æ„Ÿå‹•ã—ãŸï¼',
            
            # è³ªå•ãƒ»ç›¸è«‡
            'ã©ã†ã—ãŸã‚‰ã†ã¾ããªã‚‹ï¼Ÿ', 'å¤¢ã‚’å¶ãˆã‚‹ç§˜è¨£ã¯ï¼Ÿ', 'å›°ã£ãŸæ™‚ã¯ã©ã†ã™ã‚‹ï¼Ÿ',
            'é‡çƒã®æ¥½ã—ã•ã£ã¦ï¼Ÿ', 'ãƒ—ãƒ­ã«ãªã‚‹ã«ã¯ï¼Ÿ', 'ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãã ã•ã„',
        ]
        
        answers = [
            # æŒ¨æ‹¶ãƒ»æ—¥å¸¸ä¼šè©±ã®è¿”ç­”
            'ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã‚‚ä¸€æ—¥é ‘å¼µã‚Šã¾ã—ã‚‡ã†ï¼', 'ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ï¼ä»Šæ—¥ã‚‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™',
            'ä»Šæ—¥ã¯ã¨ã¦ã‚‚èª¿å­ãŒã„ã„ã§ã™ï¼ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™', 'ãŠç–²ã‚Œã•ã¾ã§ã™ï¼ä»Šæ—¥ã‚‚é ‘å¼µã‚Šã¾ã—ãŸ',
            'ã¯ã„ã€ãŠã‹ã’ã•ã¾ã§å…ƒæ°—ã§ã™ï¼', 'æœ€è¿‘ã¯å……å®Ÿã—ãŸæ—¥ã€…ã‚’é€ã‚Œã¦ã„ã¾ã™',
            'ã“ã‚“ã°ã‚“ã¯ï¼ä»Šæ—¥ã‚‚ä¸€æ—¥ãŠç–²ã‚Œã•ã¾ã§ã—ãŸ', 'ãŠã‚„ã™ã¿ãªã•ã„ã€è‰¯ã„å¤¢ã‚’ï¼',
            
            # é‡çƒé–¢é€£ã®è¿”ç­”
            'ä»Šæ—¥ã®è©¦åˆã¯ãƒãƒ¼ãƒ ä¸€ä¸¸ã¨ãªã£ã¦æˆ¦ãˆã¾ã—ãŸ', 'ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°ã¯æ—¥ã€…ã®ç©ã¿é‡ã­ãŒå¤§åˆ‡ã§ã™ã­',
            'ãƒ”ãƒƒãƒãƒ³ã‚°ã§ã¯ä¸€çƒä¸€çƒé›†ä¸­ã—ã¦ã„ã¾ã™', 'ãƒãƒ¼ãƒ ã®é›°å›²æ°—ã¯æœ¬å½“ã«ç´ æ™´ã‚‰ã—ã„ã§ã™',
            'ä»Šã‚·ãƒ¼ã‚ºãƒ³ã¯ãƒãƒ¼ãƒ å„ªå‹ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™', 'ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚‚æ¥½ã—ã¿ã®ä¸€ã¤ã ã¨æ€ã„ã¾ã™',
            
            # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã®è¿”ç­”
            'ä»Šã¯ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ãªãŒã‚‰æœ¬ã‚’èª­ã‚“ã§ã„ã¾ã™', 'å’Œé£Ÿã€ç‰¹ã«ãŠæ¯ã•ã‚“ã®æ‰‹æ–™ç†ãŒæ‹ã—ã„ã§ã™',
            'èª­æ›¸ã‚„æ˜ ç”»é‘‘è³ãŒå¥½ãã§ã™ã­', 'ä¼‘æ—¥ã¯è‡ªç„¶ã®ä¸­ã§éã”ã™ã“ã¨ãŒå¤šã„ã§ã™',
            'ã¯ã„ã€æ™‚é–“ãŒã‚ã‚‹æ™‚ã¯æ˜ ç”»ã‚’è¦‹ã¾ã™', 'éŸ³æ¥½ã‚’èã„ã¦ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ã¦ã„ã¾ã™',
            'æ—¥æœ¬ã®å®¶æ—ã‚„å‹äººãŒæ‹ã—ã„ã§ã™ã­', 'ã‚¢ãƒ¡ãƒªã‚«ã§ã‚‚å¤šãã®ã“ã¨ã‚’å­¦ã‚“ã§ã„ã¾ã™',
            
            # åŠ±ã¾ã—ãƒ»å¿œæ´ã¸ã®è¿”ç­”
            'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼é ‘å¼µã‚Šã¾ã™ï¼', 'å¿œæ´ã—ã¦ãã ã•ã£ã¦æœ¬å½“ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼',
            'ãã®è¨€è‘‰ãŒåŠ›ã«ãªã‚Šã¾ã™ï¼', 'çš†ã•ã‚“ã®å¿œæ´ãŒã‚ã‚‹ã‹ã‚‰ã“ãã§ã™',
            'ãã†è¨€ã£ã¦ã‚‚ã‚‰ãˆã¦å¬‰ã—ã„ã§ã™', 'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼ã¨ã¦ã‚‚åŠ±ã¿ã«ãªã‚Šã¾ã™',
            'æ„Ÿå‹•ã—ã¦ã„ãŸã ã‘ã¦å…‰æ „ã§ã™',
            
            # è³ªå•ãƒ»ç›¸è«‡ã¸ã®è¿”ç­”
            'æ¯æ—¥ã®ç©ã¿é‡ã­ãŒä¸€ç•ªå¤§åˆ‡ã ã¨æ€ã„ã¾ã™', 'å¤¢ã‚’æŒã¡ç¶šã‘ã‚‹ã“ã¨ãŒä½•ã‚ˆã‚Šå¤§åˆ‡ã§ã™',
            'å›°ã£ãŸæ™‚ã¯åŸºæœ¬ã«ç«‹ã¡è¿”ã‚‹ã“ã¨ã‚’å¿ƒãŒã‘ã¦ã„ã¾ã™', 'é‡çƒã¯äººã¨äººã‚’ã¤ãªãç´ æ™´ã‚‰ã—ã„ã‚¹ãƒãƒ¼ãƒ„ã§ã™',
            'ãƒ—ãƒ­ã«ãªã‚‹ã«ã¯ã€ã¾ãšé‡çƒã‚’å¿ƒã‹ã‚‰æ¥½ã—ã‚€ã“ã¨ã§ã™', 'å¸¸ã«è¬™è™šã•ã‚’å¿˜ã‚Œãšã«åŠªåŠ›ã™ã‚‹ã“ã¨ãŒå¤§åˆ‡ã§ã™',
        ]
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’åŒã˜é•·ã•ã«èª¿æ•´
        max_len = max(len(questions), len(answers))
        while len(questions) < max_len:
            questions.extend(questions[:max_len-len(questions)])
        while len(answers) < max_len:
            answers.extend(answers[:max_len-len(answers)])
        
        return pd.DataFrame({
            'ID': range(1, len(questions) + 1),
            'Question': questions[:max_len],
            'Answer': answers[:max_len]
        })
    
    def _extract_speech_patterns(self) -> Dict:
        """ãƒãƒ£ãƒƒãƒˆå‘ã‘è©±ã—æ–¹ãƒ‘ã‚¿ãƒ¼ãƒ³"""
        return {
            'greetings': {
                'morning': ['ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ï¼', 'ãŠã¯ã‚ˆã†ï¼ä»Šæ—¥ã‚‚ã‚ˆã‚ã—ãï¼'],
                'day': ['ã“ã‚“ã«ã¡ã¯ï¼', 'ã“ã‚“ã«ã¡ã¯ï¼èª¿å­ã¯ã©ã†ã§ã™ã‹ï¼Ÿ'],
                'evening': ['ã“ã‚“ã°ã‚“ã¯ï¼', 'ã“ã‚“ã°ã‚“ã¯ï¼ãŠç–²ã‚Œã•ã¾ã§ã—ãŸ'],
                'night': ['ãŠã‚„ã™ã¿ãªã•ã„ï¼', 'ãŠã‚„ã™ã¿ï¼è‰¯ã„å¤¢ã‚’']
            },
            'starters': ['ãã†ã§ã™ã­', 'ã†ãƒ¼ã‚“', 'ã‚ãƒ¼', 'ãã†ãã†', 'ãªã‚‹ã»ã©', 'å®Ÿã¯'],
            'endings': ['ã§ã™ï¼', 'ã§ã™ã­', 'ã¨æ€ã„ã¾ã™', 'ã‹ãª', 'ã‚ˆ', 'ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“'],
            'reactions': ['ãã‚Œã¯ã„ã„ã§ã™ã­ï¼', 'ã‚ã‹ã‚Šã¾ã™ï¼', 'ãã†ãªã‚“ã§ã™', 'ãªã‚‹ã»ã©ï¼'],
            'emotions': ['å¬‰ã—ã„ã§ã™', 'æ¥½ã—ã„ã§ã™ã­', 'ã‚ã‚ŠãŒãŸã„ã§ã™', 'æ„Ÿè¬ã—ã¦ã„ã¾ã™'],
            'casual': ['ã¯ã„', 'ãã†', 'ã†ã‚“', 'ãªã‚‹ã»ã©', 'ã‚ã‹ã‚Šã¾ã—ãŸ', 'ãã†ã‹ã‚‚']
        }
    
    def _create_chat_patterns(self) -> Dict:
        """ãƒãƒ£ãƒƒãƒˆç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³"""
        return {
            'quick_responses': [
                'ãã†ãªã‚“ã§ã™ï¼', 'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼', 'ãªã‚‹ã»ã©ï¼', 
                'ã‚ã‹ã‚Šã¾ã™ï¼', 'ãã®é€šã‚Šã§ã™ï¼', 'ã„ã„ã§ã™ã­ï¼'
            ],
            'thinking': ['ã†ãƒ¼ã‚“...', 'ãã†ã§ã™ã­...', 'ã©ã†ã§ã—ã‚‡ã†...'],
            'agreement': ['ã¯ã„ï¼', 'ãã†ã§ã™ï¼', 'ãã®é€šã‚Šï¼', 'åŒæ„Ÿã§ã™ï¼'],
            'encouragement': ['é ‘å¼µã£ã¦ï¼', 'ãƒ•ã‚¡ã‚¤ãƒˆï¼', 'å¿œæ´ã—ã¦ã„ã¾ã™ï¼', 'å¤§ä¸ˆå¤«ï¼']
        }
    
    def chat_search(self, query: str, ai_provider: str = None, api_key: str = None) -> Dict:
        """ãƒãƒ£ãƒƒãƒˆç”¨æ¤œç´¢ï¼ˆç°¡ç•¥åŒ–ï¼‰"""
        
        # æŒ¨æ‹¶ã®æ¤œå‡º
        if self._is_greeting(query):
            return self._handle_greeting(query)
        
        # çŸ­ã„è¿”äº‹ã®æ¤œå‡º
        if self._is_short_response(query):
            return self._handle_short_response(query)
        
        # é€šå¸¸ã®RAGæ¤œç´¢
        threshold = 0.05  # é–¾å€¤ã‚’é©åº¦ã«èª¿æ•´
        
        # 1. å®Œå…¨ä¸€è‡´ãƒ»é«˜é¡ä¼¼åº¦å„ªå…ˆæ¤œç´¢
        best_match = self._find_best_match(query, threshold)
        if best_match is not None:
            idx, score, method = best_match
            return {
                'method': method,
                'response': self._make_chat_friendly(self.answers[idx]),
                'confidence': 'high' if score > 0.7 else 'medium',
                'needs_ai': False
            }
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
        keyword_results = self.keyword_search.search(query, top_k=5)
        if keyword_results and keyword_results[0][1] >= threshold:
            idx, score = keyword_results[0]
            return {
                'method': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢',
                'response': self._make_chat_friendly(self.answers[idx]),
                'confidence': 'medium',
                'needs_ai': False  # RAGãŒã‚ã‚Œã°AIç”Ÿæˆã¯ã—ãªã„
            }
        
        # AIç”ŸæˆãŒå¿…è¦
        if ai_provider and api_key:
            return {
                'method': 'AIç”Ÿæˆ',
                'response': None,
                'confidence': 'medium',
                'needs_ai': True,
                'ai_context': self._prepare_chat_ai_context(query)
            }
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return {
            'method': 'ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ',
            'response': self._generate_chat_response(query),
            'confidence': 'low',
            'needs_ai': False
        }
    
    def _is_greeting(self, query: str) -> bool:
        """æŒ¨æ‹¶ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        greetings = ['ã“ã‚“ã«ã¡ã¯', 'ãŠã¯ã‚ˆã†', 'ã“ã‚“ã°ã‚“ã¯', 'ã¯ã˜ã‚ã¾ã—ã¦', 'ã‚ˆã‚ã—ã', 'ãŠã‚„ã™ã¿']
        return any(greeting in query.lower() for greeting in greetings)
    
    def _handle_greeting(self, query: str) -> Dict:
        """æŒ¨æ‹¶ã¸ã®å¯¾å¿œ"""
        current_hour = datetime.now().hour
        
        if 'ãŠã¯ã‚ˆã†' in query:
            response = random.choice(self.ohtani_patterns['greetings']['morning'])
        elif 'ã“ã‚“ã°ã‚“ã¯' in query or 'ãŠã‚„ã™ã¿' in query:
            response = random.choice(self.ohtani_patterns['greetings']['evening'])
        else:
            response = random.choice(self.ohtani_patterns['greetings']['day'])
        
        return {
            'method': 'æŒ¨æ‹¶å¯¾å¿œ',
            'response': response,
            'confidence': 'high',
            'needs_ai': False
        }
    
    def _is_short_response(self, query: str) -> bool:
        """çŸ­ã„è¿”äº‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        short_patterns = ['ã¯ã„', 'ã†ã‚“', 'ãã†', 'ãªã‚‹ã»ã©', 'ã‚ã‹ã£ãŸ', 'ã‚ã‚ŠãŒã¨ã†', 'ã™ã”ã„']
        return len(query) <= 10 and any(pattern in query.lower() for pattern in short_patterns)
    
    def _handle_short_response(self, query: str) -> Dict:
        """çŸ­ã„è¿”äº‹ã¸ã®å¯¾å¿œ"""
        if 'ã‚ã‚ŠãŒã¨ã†' in query:
            response = 'ã“ã¡ã‚‰ã“ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼'
        elif 'ã™ã”ã„' in query or 'ç´ æ™´ã‚‰ã—ã„' in query:
            response = 'ãã†è¨€ã£ã¦ã‚‚ã‚‰ãˆã¦å¬‰ã—ã„ã§ã™ï¼'
        else:
            response = random.choice(self.chat_patterns['quick_responses'])
        
        return {
            'method': 'çŸ­æ–‡å¯¾å¿œ',
            'response': response,
            'confidence': 'high',
            'needs_ai': False
        }
    
    def _make_chat_friendly(self, response: str) -> str:
        """å›ç­”ã‚’å¤§è°·é¸æ‰‹ã‚‰ã—ã„è¨˜è€…å¯¾å¿œé¢¨ã«èª¿æ•´"""
        # é•·ã„æ–‡ã‚’çŸ­ç¸®
        if len(response) > 120:
            sentences = response.split('ã€‚')
            response = sentences[0] + 'ã€‚'
        
        # å¤§è°·é¸æ‰‹ã®è¨˜è€…å¯¾å¿œã‚‰ã—ã„è¡¨ç¾ã«èª¿æ•´ï¼ˆã€Œã‚ˆã€ã¯å‰Šé™¤ï¼‰
        # åŸºæœ¬çš„ã«ã¯RAGãƒ‡ãƒ¼ã‚¿ãã®ã¾ã¾ã‚’å°Šé‡
        
        return response
    
    def _find_best_match(self, query: str, threshold: float):
        """æœ€é©ãªãƒãƒƒãƒã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆå®Œå…¨ä¸€è‡´å„ªå…ˆï¼‰"""
        query_clean = re.sub(r'[ã€‚ã€ï¼ï¼Ÿ\s]+', '', query.lower())
        
        # 1. å®Œå…¨ä¸€è‡´ãƒ»é«˜é¡ä¼¼åº¦æ¤œç´¢
        for i, question in enumerate(self.questions):
            question_clean = re.sub(r'[ã€‚ã€ï¼ï¼Ÿ\s]+', '', question.lower())
            
            # æ–‡å­—åˆ—é¡ä¼¼åº¦è¨ˆç®—ï¼ˆç·¨é›†è·é›¢ãƒ™ãƒ¼ã‚¹ï¼‰
            similarity = self._string_similarity(query_clean, question_clean)
            
            # 90%ä»¥ä¸Šã®é¡ä¼¼åº¦ãªã‚‰æœ€å„ªå…ˆ
            if similarity >= 0.9:
                return (i, similarity, 'å®Œå…¨ä¸€è‡´æ¤œç´¢')
            
            # 80%ä»¥ä¸Šãªã‚‰é«˜å„ªå…ˆ
            elif similarity >= 0.8:
                return (i, similarity, 'é«˜é¡ä¼¼åº¦æ¤œç´¢')
        
        # 2. TF-IDFæ¤œç´¢ï¼ˆç¯„å›²æ‹¡å¤§ãƒ»è£œæ­£ï¼‰
        tfidf_results = self.tfidf_search.search(query, top_k=15)  # ç¯„å›²æ‹¡å¤§
        best_match = None
        best_score = 0
        
        # ä¸Šä½15ä»¶ã‚’è©³ç´°ãƒã‚§ãƒƒã‚¯
        for idx, score in tfidf_results[:15]:
            if score >= threshold:
                question = self.questions[idx]
                
                # æ–‡å­—åˆ—é¡ä¼¼åº¦ã‚‚è€ƒæ…®
                question_clean = re.sub(r'[ã€‚ã€ï¼ï¼Ÿ\s]+', '', question.lower())
                string_sim = self._string_similarity(query_clean, question_clean)
                
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡è¤‡åº¦
                query_keywords = set(re.findall(r'[\w\u3040-\u309f\u30a0-\u30ff\u4e00-\u9fff]+', query.lower()))
                question_keywords = set(re.findall(r'[\w\u3040-\u309f\u30a0-\u30ff\u4e00-\u9fff]+', question.lower()))
                keyword_overlap = len(query_keywords & question_keywords) / max(len(query_keywords), 1)
                
                # ç·åˆã‚¹ã‚³ã‚¢ï¼ˆTF-IDF + æ–‡å­—åˆ—é¡ä¼¼åº¦ + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡è¤‡ï¼‰
                combined_score = score * 0.4 + string_sim * 0.4 + keyword_overlap * 0.2
                
                if combined_score > best_score:
                    best_score = combined_score
                    best_match = idx
        
        if best_match is not None and best_score > 0.3:
            return (best_match, best_score, 'TF-IDFæ¤œç´¢')
        
        return None
    
    def _string_similarity(self, s1: str, s2: str) -> float:
        """æ–‡å­—åˆ—é¡ä¼¼åº¦è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆç·¨é›†è·é›¢ï¼‰"""
        if not s1 or not s2:
            return 0.0
        
        # é•·ã„æ–¹ã‚’åŸºæº–ã«ã™ã‚‹
        longer = s1 if len(s1) > len(s2) else s2
        shorter = s2 if len(s1) > len(s2) else s1
        
        if len(longer) == 0:
            return 1.0
        
        # å…±é€šéƒ¨åˆ†æ–‡å­—åˆ—ã®é•·ã•ã‚’è¨ˆç®—
        common_chars = 0
        for char in shorter:
            if char in longer:
                common_chars += 1
        
        return common_chars / len(longer)
    
    def _generate_chat_response(self, query: str) -> str:
        """ãƒãƒ£ãƒƒãƒˆå‘ã‘ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ"""
        starter = random.choice(self.ohtani_patterns['starters'])
        ending = random.choice(self.ohtani_patterns['endings'])
        
        templates = [
            f"{starter}ã€ãã‚Œã¯é¢ç™½ã„è³ªå•ã§ã™ã­ï¼",
            f"ã„ã„è³ªå•{ending}ï¼",
            f"{starter}ã€ãã®ã“ã¨ã«ã¤ã„ã¦è€ƒãˆã¦ã¿ã¾ã™ã­",
            f"ãªã‚‹ã»ã©ã€{query}ã«ã¤ã„ã¦{ending}",
        ]
        
        return random.choice(templates)
    
    def _prepare_chat_ai_context(self, query: str) -> str:
        """ãƒãƒ£ãƒƒãƒˆç”¨AIç”Ÿæˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
        return f"""
ã‚ãªãŸã¯å¤§è°·ç¿”å¹³é¸æ‰‹ã¨ã—ã¦ã€è¨˜è€…ã«å¯¾å¿œã™ã‚‹ã¨ãã¨åŒã˜ã‚ˆã†ãªæ„Ÿã˜ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã€ç‰¹å¾´ã€‘
- çµµæ–‡å­—ã¯ä½¿ã‚ãªã„ï¼ˆæ—¥æœ¬èªã®è‡ªç„¶ãªè¡¨ç¾ã§ï¼‰
- 70-100æ–‡å­—ç¨‹åº¦
- ä»¥ä¸‹ã®ã‚ˆã†ãªå¤§è°·ç¿”å¹³é¸æ‰‹ã‚‰ã—ã„å£èª¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
  ç‰¹ã«ä¸€ç•ªæœ€å¾Œã®4ãŒå¤§åˆ‡ã§ã™ã€‚
    1. è¬™è™šã•ã¨èª å®Ÿã•
        ã€Œã¾ã‚ã€ãã†ã§ã™ã­ã€ã‹ã‚‰å§‹ã‚ã‚‹ã“ã¨ãŒå¤šã„
        ã€Œã€œã‹ãªã¨æ€ã„ã¾ã™ã€ã€Œã€œã ã£ãŸã‚“ã˜ã‚ƒãªã„ã‹ãªã¨æ€ã„ã¾ã™ã€
        ã€Œç‰¹åˆ¥ãªã“ã¨ã§ã¯ãªã„ã§ã™ãŒã€ã€Œã‚ã¾ã‚Šæ„è­˜ã—ã¦ã„ãªã„ã‚“ã§ã™ãŒã€
        ã€Œå€‹äººçš„ã«ã¯ã€ã€Œåƒ•ã®ä¸­ã§ã¯ã€
        ã€Œé‹ã‚‚è‰¯ã‹ã£ãŸã¨æ€ã„ã¾ã™ã€ã€Œãƒ©ãƒƒã‚­ãƒ¼ã ã£ãŸã¨æ€ã„ã¾ã™ã€
    2. è«–ç†çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„èª¬æ˜
        ã€Œã€œã¨ã„ã†è¦³ç‚¹ã§ã€ã€Œã€œã«æ¯”ã¹ã‚‹ã¨ã€ã€Œã€œã¨ã„ã†ã‚ˆã‚Šã‚‚ã€
        ã€Œã€œã¨ã„ã†éƒ¨åˆ†ã§ã¯ã€ã€Œã€œã¨ã„ã†é¢¨ã«ã€ã€Œã€œã¨ã„ã†æ„Ÿã˜ã§ã™ã€
        ã€ŒåŸºæœ¬çš„ã«ã€ã€Œçµæœçš„ã«ã€ã€Œãã®ãŸã‚ã«ã€ã€Œã€œã ã¨æ€ã£ã¦ã„ã‚‹ã®ã§ã€
    3. ãƒã‚¸ãƒ†ã‚£ãƒ–ã§å‰å‘ããªå§¿å‹¢
        ã€Œãã‚Œã¯ã‚‚ã†ã€ã‚„ã‚‹ã—ã‹ãªã„ã§ã™ã€
        ã€Œã™ã”ãã€œã ã¨æ€ã„ã¾ã™ã€ã€Œã‚‚ã£ã¨ã€œã—ã¦ã„ããŸã„ã§ã™ã€
        ã€Œè‡ªåˆ†ã®ã‚„ã‚‹ã¹ãã“ã¨ã¯å¤‰ã‚ã‚‰ãªã„ã®ã§ã€
        ã€Œãã“ã¯ã€ã‚‚ã†åˆ‡ã‚Šæ›¿ãˆã¦ã€ã€Œæ¬¡ã®æ©Ÿä¼šã«ã€
        ã€Œãƒãƒ¼ãƒ ãŒå‹ã¤ã“ã¨ãŒä¸€ç•ªãªã®ã§ã€ã€Œã§ãã‚‹ã“ã¨ã¯å…¨éƒ¨ã‚„ã‚‹ã€ã€Œã‚‚ã¡ã‚ã‚“ã€
    4. ç‰¹å¾´çš„ãªæ–‡æœ«ãƒ‘ã‚¿ãƒ¼ãƒ³
        ã€Œã€œã¨ã„ã†æ„Ÿã˜ã˜ã‚ƒãªã„ã‹ãªã¨æ€ã„ã¾ã™ã€ã€Œã€œã‹ãªã¨æ€ã„ã¾ã™ã€
        ã€Œã€œã‚“ã˜ã‚ƒãªã„ã‹ãªã¨æ€ã„ã¾ã™ã€

è³ªå•: {query}

å¤§è°·ç¿”å¹³ã¨ã—ã¦è‡ªç„¶ã«è¿”ç­”:"""

# AI APIå‘¼ã³å‡ºã—ï¼ˆãƒãƒ£ãƒƒãƒˆç”¨ï¼‰
def call_ai_for_chat(context: str, ai_provider: str, api_key: str) -> Optional[str]:
    """ãƒãƒ£ãƒƒãƒˆç”¨AIå‘¼ã³å‡ºã—"""
    try:
        if ai_provider == "Gemini":
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            
            model = genai.GenerativeModel("gemini-1.5-flash")
            response = model.generate_content(
                context,
                generation_config=genai.GenerationConfig(
                    max_output_tokens=150,
                    temperature=0.9,
                    top_p=0.95
                )
            )
            return response.text if hasattr(response, 'text') else None
            
        elif ai_provider == "OpenAI":
            headers = {'Authorization': f'Bearer {api_key}', 'Content-Type': 'application/json'}
            data = {
                'model': 'gpt-3.5-turbo',
                'messages': [{'role': 'user', 'content': context}],
                'max_tokens': 120,
                'temperature': 0.9
            }
            
            response = requests.post('https://api.openai.com/v1/chat/completions', 
                                   headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                return response.json()['choices'][0]['message']['content']
            else:
                return f"API ã‚¨ãƒ©ãƒ¼: {response.status_code}"
                
    except Exception as e:
        return f"AI ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ç®¡ç†
def initialize_chat():
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–"""
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
        # æœ€åˆã®æŒ¨æ‹¶ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        st.session_state.chat_history.append({
            'type': 'ohtani',
            'message': 'AIå¤§è°·ã§ã™ã€‚ãƒãƒ£ãƒƒãƒˆã—ãªã‹ã£ãŸã‚‰ã—ãªã‹ã£ãŸã§ã€ã¿ãªã•ã‚“ã†ã‚‹ã•ã„ã§ã™ã—ã€èããŸã„ã“ã¨ãŒã‚ã‚Œã°èãã¾ã™ã€‚',
            'timestamp': datetime.now().strftime('%Hæ™‚%Måˆ†'),
            'method': 'åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸'
        })

def add_message(message_type: str, message: str, method: str = ''):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ """
    st.session_state.chat_history.append({
        'type': message_type,
        'message': message,
        'timestamp': datetime.now().strftime('%Hæ™‚%Måˆ†'),
        'method': method
    })

def display_chat_messages():
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º"""
    chat_html = '<div class="chat-background">'
    
    for i, msg in enumerate(st.session_state.chat_history):
        timestamp = msg.get("timestamp", "")
        # æ—¢ã«HTMLã¨ã—ã¦æ•´å½¢æ¸ˆã¿ã®éƒ¨åˆ†ã¯ãã®ã¾ã¾ã€é€šå¸¸ãƒ†ã‚­ã‚¹ãƒˆã¯ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
        raw_message = str(msg.get("message", ""))
        if raw_message.strip().startswith("<") and raw_message.strip().endswith(">"):
            safe_message = raw_message
        else:
            safe_message = html.escape(raw_message).replace("\n", "<br>")
        
        if msg['type'] == 'user':
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä¸­èº«ã«HTMLã‚¿ã‚°ã‚’å«ã‚€å ´åˆã§ã‚‚ã€ãƒãƒ£ãƒƒãƒˆã®HTMLã¯å›ºå®šæ§‹é€ ã¨ã—ã¦å‡ºåŠ›
            chat_html += '<div class="user-message-container">'
            chat_html += f'<div class="user-message">{safe_message}</div>'
            chat_html += '<div class="user-avatar">YOU</div>'
            chat_html += '</div>'
            chat_html += f'<div class="timestamp">{timestamp}</div>'
        elif msg['type'] == 'ohtani':
            chat_html += '<div class="ohtani-message-container">'
            chat_html += '<div class="ohtani-avatar">ğŸ¶</div>'
            chat_html += f'<div class="ohtani-message">{safe_message}</div>'
            chat_html += '</div>'
            # æ¤œç´¢æ–¹æ³•ã‚’æ™‚é–“ã®å‰ã«è¡¨ç¤º
            if msg.get("method") and msg.get("method") != 'åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸':
                chat_html += f'<div class="system-message">{html.escape(str(msg.get("method", "")))}</div>'
            chat_html += f'<div class="timestamp">{timestamp}</div>'
        elif msg['type'] == 'system':
            chat_html += f'<div class="system-message">{msg["message"]}</div>'
        elif msg['type'] == 'typing':
            chat_html += f'''
            <div class="typing-container">
                <div class="ohtani-avatar">ğŸ¶</div>
                <div class="typing-indicator">
                    å¤§è°·é¸æ‰‹ãŒå…¥åŠ›ä¸­
                    <div class="typing-dots">
                        <div class="typing-dot"></div>
                        <div class="typing-dot"></div>
                        <div class="typing-dot"></div>
                    </div>
                </div>
            </div>
            '''
    
    chat_html += '</div>'
    return chat_html

def show_quick_replies():
    """ã‚¯ã‚¤ãƒƒã‚¯è¿”ä¿¡ãƒœã‚¿ãƒ³"""
    st.markdown('''
    <div class="quick-replies">
    ''', unsafe_allow_html=True)
    
    quick_questions = [
        "ä»Šæ—¥èª¿å­ã¯ã©ã†ï¼Ÿ", "é‡çƒã®è©±èã‹ã›ã¦", "å¥½ããªé£Ÿã¹ç‰©ã¯ï¼Ÿ", 
        "ä»Šä½•ã—ã¦ã‚‹ã®ï¼Ÿ", "å¿œæ´ã—ã¦ã‚‹ã‚ˆï¼", "ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãã ã•ã„"
    ]
    
    # ãƒœã‚¿ãƒ³ã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤º
    cols = st.columns(len(quick_questions))
    selected_question = None
    
    for i, question in enumerate(quick_questions):
        with cols[i]:
            if st.button(question, key=f"quick_{i}", help=f"ã‚¯ã‚¤ãƒƒã‚¯é€ä¿¡: {question}"):
                selected_question = question
    
    st.markdown('</div>', unsafe_allow_html=True)
    return selected_question

# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    # CSSèª­ã¿è¾¼ã¿
    load_css()
    
    # ãƒšãƒ¼ã‚¸ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
    current_page = show_page_navigation()
    
    # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã«å¿œã˜ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¡¨ç¤º
    if current_page == 'home':
        show_home_page()
    elif current_page == 'chat':
        show_chat_page()
    elif current_page == 'extraction':
        show_extraction_page()
    elif current_page == 'settings':
        show_settings_page()

def show_chat_page():
    # CSSèª­ã¿è¾¼ã¿
    load_css()
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´åˆæœŸåŒ–
    initialize_chat()
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼HTML
    header_html = textwrap.dedent('''
    <div class="chat-header">
        AIå¤§è°·ã¨ãƒãƒ£ãƒƒãƒˆ
        <div class="status-indicator">
            <div class="online-dot"></div>
            ã‚ªãƒ³ãƒ©ã‚¤ãƒ³
        </div>
    </div>
    ''')
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆè¨­å®šï¼‰
    with st.sidebar:
        st.header("âš™ï¸ ãƒãƒ£ãƒƒãƒˆè¨­å®š")
        
        # AIè¨­å®š
        ai_provider = st.selectbox("ğŸ¤– AIç”Ÿæˆ", ["ãªã—", "Gemini", "OpenAI"])
        api_key = ""
        
        if ai_provider == "Gemini":
            api_key = st.text_input("Gemini API Key", type="password", 
                                  value=os.getenv("GEMINI_API_KEY", ""))
        elif ai_provider == "OpenAI":
            api_key = st.text_input("OpenAI API Key", type="password",
                                  value=os.getenv("OPENAI_API_KEY", ""))
        
        use_ai = ai_provider != "ãªã—" and bool(api_key)
        
        if use_ai:
            st.success(f"âœ… {ai_provider} æ¥ç¶šä¸­")
        else:
            st.info("ğŸ’¬ ãƒ‘ã‚¿ãƒ¼ãƒ³å¿œç­”ãƒ¢ãƒ¼ãƒ‰")
        
        st.divider()
        
        # çµ±è¨ˆæƒ…å ±
        total_messages = len(st.session_state.chat_history)
        user_messages = len([m for m in st.session_state.chat_history if m['type'] == 'user'])
        ohtani_messages = len([m for m in st.session_state.chat_history if m['type'] == 'ohtani'])
        
        st.metric("ğŸ’¬ ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°", total_messages)
        st.metric("ğŸ‘¤ ã‚ãªãŸã®ç™ºè¨€", user_messages)
        st.metric("ğŸ¶ å¤§è°·é¸æ‰‹ã®è¿”ç­”", ohtani_messages)
        
        # ä»Šæ—¥ã®å¤§è°·æƒ…å ±ï¼ˆæ¥½ã—ã„è¦ç´ ï¼‰
        with st.expander("ğŸ“Š ä»Šæ—¥ã®å¤§è°·é¸æ‰‹"):
            st.write("âš¾ ç·´ç¿’: ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°ç·´ç¿’å®Œäº†")
            st.write("ğŸƒ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°: ãƒ©ãƒ³ãƒ‹ãƒ³ã‚° 5km")
            st.write("ğŸ“š å‹‰å¼·: è‹±èªå­¦ç¿’ 30åˆ†")
            st.write("ğŸ¶ ãƒ‡ã‚³ãƒ”ãƒ³: ãŠæ•£æ­©æ¸ˆã¿")
            st.write("ğŸ˜Š ä»Šæ—¥ã®æ°—åˆ†: çµ¶å¥½èª¿ï¼")
            
        with st.expander("ğŸ’¡ ä½¿ã„æ–¹ã®ã‚³ãƒ„"):
            st.markdown("""
            **è‡ªç„¶ã«è©±ã—ã‹ã‘ã¦ã¿ã¦ï¼**
            
            ğŸ—£ï¸ **ã“ã‚“ãªè©±é¡ŒãŒãŠã™ã™ã‚:**
            - ä»Šæ—¥ã®èª¿å­ã‚„æ°—åˆ†
            - é‡çƒã®ã“ã¨
            - å¥½ããªé£Ÿã¹ç‰©ã‚„è¶£å‘³  
            - å¿œæ´ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            - ç›¸è«‡ã‚„è³ªå•
            
            ğŸ¤– **AIãƒ¢ãƒ¼ãƒ‰ (APIã‚­ãƒ¼è¨­å®šæ™‚):**
            - ã‚ˆã‚Šè‡ªç„¶ã§å¤šæ§˜ãªä¼šè©±
            - æ–°ã—ã„è³ªå•ã«ã‚‚å¯¾å¿œ
            - å¤§è°·é¸æ‰‹ã‚‰ã—ã„è¿”ç­”
            
            ğŸ’¬ **ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ¢ãƒ¼ãƒ‰:**
            - åŸºæœ¬çš„ãªä¼šè©±ã«å¯¾å¿œ
            - å®‰å®šã—ãŸè¿”ç­”
            - APIã‚­ãƒ¼ä¸è¦
            """)
        
        # ä¸€ç•ªä¸‹ã«ãƒãƒ£ãƒƒãƒˆæ“ä½œãƒœã‚¿ãƒ³ï¼ˆã‚°ãƒ¬ãƒ¼ï¼‰
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("å±¥æ­´ã‚¯ãƒªã‚¢", key="clear_history", help="ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
                st.session_state.chat_history = []
                initialize_chat()
                st.rerun()
        
        with col2:
            if st.button("ãƒšãƒ¼ã‚¸æ›´æ–°", key="page_refresh", help="ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°"):
                st.rerun()
    
    # RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    @st.cache_resource
    def load_chat_rag():
        return OhtaniChatRAG('ohtani_rag_final.csv')
    
    rag = load_chat_rag()
    
    # ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆç”»é¢ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã§å¸¸ã«ç½®æ›æç”»ï¼‰
    chat_container = st.empty()
    def render_chat(body_html: str):
        chat_container.markdown(f'<div class="chat-app">{header_html}{body_html}</div>', unsafe_allow_html=True)

    render_chat(display_chat_messages())
    
    # ã‚¯ã‚¤ãƒƒã‚¯è¿”ä¿¡ï¼ˆéè¡¨ç¤ºåŒ–ï¼‰
    # quick_reply = show_quick_replies()
    # if quick_reply:
    #     st.session_state.user_input = quick_reply
    #     st.rerun()
    
    # å…¥åŠ›ã‚¨ãƒªã‚¢
    st.markdown('<div class="input-area">', unsafe_allow_html=True)
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›
    col1, col2 = st.columns([4, 1])
    
    with col1:
        user_input = st.text_input(
            "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›...", 
            key="message_input",
            placeholder="å¤§è°·é¸æ‰‹ã«è©±ã—ã‹ã‘ã¦ã¿ã‚ˆã†ï¼",
            label_visibility="collapsed"
        )
    
    with col2:
        send_button = st.button("é€ä¿¡", type="primary", use_container_width=True)
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡å‡¦ç†
    if (send_button and user_input.strip()) or hasattr(st.session_state, 'user_input'):
        
        if hasattr(st.session_state, 'user_input'):
            user_input = st.session_state.user_input
            delattr(st.session_state, 'user_input')
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        add_message('user', user_input)
        
        # ã‚¿ã‚¤ãƒ”ãƒ³ã‚°è¡¨ç¤ºï¼ˆåŒã˜ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’æ›´æ–°ï¼‰
        typing_inner = textwrap.dedent('''
        <div class="typing-container">
            <div class="ohtani-avatar">ğŸ¶</div>
            <div class="typing-indicator">
                å¤§è°·é¸æ‰‹ãŒå…¥åŠ›ä¸­
                <div class="typing-dots">
                    <div class="typing-dot"></div>
                    <div class="typing-dot"></div>
                    <div class="typing-dot"></div>
                </div>
            </div>
        </div>
        ''')
        body_html = display_chat_messages()
        if body_html.strip().endswith('</div>'):
            body_html = body_html[:-6] + typing_inner + '</div>'
        render_chat(body_html)
        
        # å°‘ã—å¾…æ©Ÿï¼ˆãƒªã‚¢ãƒ«æ„Ÿæ¼”å‡ºï¼‰
        time.sleep(random.uniform(1.0, 2.0))
        
        # RAGæ¤œç´¢ãƒ»AIç”Ÿæˆ
        try:
            result = rag.chat_search(user_input, ai_provider if use_ai else None, api_key if use_ai else None)
            
            ohtani_response = result['response']
            method = result['method']
            
            # AIç”ŸæˆãŒå¿…è¦ãªå ´åˆ
            if result.get('needs_ai') and use_ai:
                ai_response = call_ai_for_chat(result['ai_context'], ai_provider, api_key)
                if ai_response and not ai_response.startswith(('API', 'AI')):
                    ohtani_response = ai_response.strip()
                    method = f"{ai_provider} AIç”Ÿæˆ"
                # ç”Ÿæˆå¤±æ•—ã‚„APIã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if not ohtani_response:
                    ohtani_response = rag._generate_chat_response(user_input)
                    method = f"{method}â†’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"
            
            # å¤§è°·é¸æ‰‹ã®è¿”ç­”ã‚’è¿½åŠ 
            add_message('ohtani', ohtani_response, method)
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®å¯¾å¿œ
            add_message('ohtani', 'ã™ã¿ã¾ã›ã‚“ã€ã¡ã‚‡ã£ã¨è€ƒãˆãŒã¾ã¨ã¾ã‚‰ãªãã¦...ğŸ˜… ã‚‚ã†ä¸€åº¦è©±ã—ã‹ã‘ã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ', 'ã‚¨ãƒ©ãƒ¼å¯¾å¿œ')
        
        # ã‚¿ã‚¤ãƒ”ãƒ³ã‚°è¡¨ç¤ºã‚’å‰Šé™¤ã—ã¦å†æç”»
        render_chat(display_chat_messages())
        st.rerun()
    
    # ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±ï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
    st.markdown("---")
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col1:
        chat_count = len([m for m in st.session_state.chat_history if m['type'] == 'user'])
        st.metric("ä¼šè©±æ•°", f"{chat_count}å›")
    
    with col2:
        st.markdown("#### ğŸ¶ AIå¤§è°·ã¨ãƒãƒ£ãƒƒãƒˆä¸­")
        if use_ai:
            st.success("ğŸ¤– AIå¼·åŒ–ãƒ¢ãƒ¼ãƒ‰")
        else:
            st.info("ğŸ’¬ åŸºæœ¬ãƒ¢ãƒ¼ãƒ‰")
    
    with col3:
        st.metric("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", len(st.session_state.chat_history))

if __name__ == "__main__":
    main()